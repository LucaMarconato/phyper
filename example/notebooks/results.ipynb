{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You have to change the path in the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~/programming/python/phyper/example'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from config import instances, Instance\n",
    "from dataset import Iris\n",
    "from paths import get_cross_validation_scores_path, get_training_metrics_path\n",
    "from IPython.display import display\n",
    "from paths import jupyter_plot\n",
    "# orca has been installed with `brew cask install orca`\n",
    "import plotly\n",
    "plotly.io.orca.config.executable = '/usr/local/Caskroom/orca/1.3.1/orca.app/Contents/MacOS/orca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from score_models import get_last_epoch\n",
    "\n",
    "all_scores = pd.DataFrame(columns=['instance_hash', 'training_loss', 'training_accuracy', 'validation_loss', 'validation_accuracy'])\n",
    "rows = []\n",
    "for instance in instances:\n",
    "    path = get_training_metrics_path(instance)\n",
    "    with h5py.File(path, 'r') as f5:\n",
    "        keys = f5.keys()\n",
    "        last_epoch = get_last_epoch(keys)\n",
    "        metrics = f5[f'epoch{last_epoch}']\n",
    "        training_loss = metrics['training_loss']\n",
    "        training_accuracy = metrics['training_accuracy']\n",
    "        validation_loss = metrics['validation_loss']\n",
    "        validation_accuracy = metrics['validation_accuracy']\n",
    "        rows.append({'instance_hash': instance.get_instance_hash(),\n",
    "                     'training_loss': metrics['training_loss'][...].item(),\n",
    "                     'training_accuracy': metrics['training_accuracy'][...].item(),\n",
    "                     'validation_loss': metrics['validation_loss'][...].item(),\n",
    "                     'validation_accuracy': metrics['validation_accuracy'][...].item()})\n",
    "all_scores = all_scores.append(rows, ignore_index=True)\n",
    "all_scores.sort_values(by=['instance_hash'], inplace=True)\n",
    "cv_scores = pd.read_csv(get_cross_validation_scores_path())\n",
    "models = Instance.get_resources(instances, resource_name='cross_validated_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 5))\n",
    "# plt.pcolor(all_scores[['training_loss', 'validation_loss']])\n",
    "plt.pcolor(all_scores[['training_accuracy', 'validation_accuracy']])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f(column_name):\n",
    "    column = all_scores[[column_name]]\n",
    "    v = column.to_numpy()\n",
    "    m = v.reshape((-1, instance.cv_k)).transpose()\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.matshow(m, fignum=0)\n",
    "    plt.colorbar(orientation='horizontal')\n",
    "    plt.title(column_name)\n",
    "    plt.xlabel('instances')\n",
    "    plt.ylabel('cv fold')\n",
    "    plt.show()\n",
    "\n",
    "f('training_accuracy')\n",
    "f('validation_accuracy')\n",
    "f('training_loss')\n",
    "f('validation_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def g(column_name):\n",
    "    m = all_scores[[column_name]].to_numpy().reshape((-1, instance.cv_k))\n",
    "    means = np.mean(m, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(means)\n",
    "    plt.title('histogram of mean ' + column_name)\n",
    "    plt.show()\n",
    "\n",
    "g('training_loss')\n",
    "g('validation_loss')\n",
    "g('training_accuracy')\n",
    "g('validation_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parallel_df = all_scores.copy()\n",
    "parallel_df.set_index(keys=['instance_hash'], inplace=True)\n",
    "parallel_df['transformation'] = None\n",
    "parallel_df['centering'] = None\n",
    "parallel_df['n_hidden_layers'] = None\n",
    "transformations = {}\n",
    "for instance in instances:\n",
    "    instance_hash = instance.get_instance_hash()\n",
    "    parallel_df.at[instance_hash, 'transformation'] = instance.transformation\n",
    "    parallel_df.at[instance_hash, 'centering'] = instance.centering\n",
    "    parallel_df.at[instance_hash, 'n_hidden_layers'] = instance.n_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected = True)\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.parallel_coordinates(parallel_df[['training_loss', 'validation_loss', 'training_accuracy', 'validation_accuracy']], color='validation_accuracy', color_continuous_scale=px.colors.diverging.Tealrose, title='Relation between losses and accuracies')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1600,\n",
    "    height=800\n",
    ")\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parallel_df.sort_values(by=['validation_accuracy', 'n_hidden_layers'], ascending=False, inplace=True)\n",
    "df = px.data.tips()\n",
    "fig = px.parallel_categories(parallel_df, dimensions=['transformation', 'centering', 'n_hidden_layers', 'validation_accuracy'],\n",
    "                color='validation_accuracy', color_continuous_scale=px.colors.sequential.Inferno,\n",
    "                labels={'transformation': 'Transformation', 'centering': 'Centering', 'n_hidden_layers': '# hidden layers', 'validation_accuracy': 'Validation accuracy'},\n",
    "                title='Effect of the hyperparameters on validation accuracy')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1600,\n",
    "    height=800\n",
    ")\n",
    "fig.write_image(jupyter_plot('parallel_categories.png'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "p_df = parallel_df.copy()\n",
    "transformation_k = list(set(parallel_df['transformation'].tolist()))\n",
    "transformation_v = list(range(len(transformation_k)))\n",
    "transformation_d = dict(zip(transformation_k, transformation_v))\n",
    "p_df['transformation'] = p_df['transformation'].apply(lambda x: transformation_d[x])\n",
    "p_df['centering'] = p_df['centering'].apply(lambda x: int(x))\n",
    "\n",
    "# display(p_df.head(10))\n",
    "# for x in p_df.iloc[0]:\n",
    "#     print(type(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=\n",
    "    go.Parcoords(\n",
    "        line = dict(color = p_df['validation_accuracy'],\n",
    "            colorscale = 'Viridis',\n",
    "            showscale = True,\n",
    "            cmin = p_df['validation_accuracy'].min(),\n",
    "            cmax = p_df['validation_accuracy'].max()),\n",
    "        dimensions = list([\n",
    "            dict(range = [min(transformation_v), max(transformation_v)],\n",
    "                 tickvals = transformation_v,\n",
    "                 ticktext = transformation_k,\n",
    "                 label = 'Transformation', values = p_df['transformation'].tolist()),\n",
    "            dict(range = [0, 1],\n",
    "                 tickvals = [0, 1],\n",
    "                 ticktext = ['No', 'Yes'],\n",
    "                 label = 'Centering', values = p_df['centering'].tolist()),\n",
    "            dict(range = [p_df['n_hidden_layers'].min(), p_df['n_hidden_layers'].max()],\n",
    "                 tickvals = p_df['n_hidden_layers'].unique().tolist(),\n",
    "                 label = '# hidden layers', values = p_df['n_hidden_layers'].tolist()),\n",
    "            dict(range = [p_df['training_accuracy'].min(), p_df['training_accuracy'].max()],\n",
    "                 label = 'Training accuracy', values = p_df['training_accuracy'].tolist()),\n",
    "            dict(range = [p_df['validation_accuracy'].min(), p_df['validation_accuracy'].max()],\n",
    "                 label = 'validation accuracy', values = p_df['validation_accuracy'].tolist()),\n",
    "            dict(range = [p_df['training_loss'].min(), p_df['training_loss'].max()],\n",
    "                 label = 'Training loss', values = p_df['training_loss'].tolist()),\n",
    "            dict(range = [p_df['validation_loss'].min(), p_df['validation_loss'].max()],\n",
    "                 label = 'validation loss', values = p_df['validation_loss'].tolist()),\n",
    "            # dict(range = [1,5],\n",
    "            #      tickvals = [1,2,4,5],\n",
    "            #      label = 'C', values = [2,4],\n",
    "            #      ticktext = ['text 1', 'text 2', 'text 3', 'text 4']),\n",
    "            # dict(range = [1,5],\n",
    "            #      label = 'D', values = [4,2])\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title='Effect of the hyperparameters on validation accuracy',\n",
    "    autosize=False,\n",
    "    width=1600,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
